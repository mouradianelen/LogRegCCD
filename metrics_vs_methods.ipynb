{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LogRegCCD\n",
    "from dataset import generate_synth_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    recall_score,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_df = pd.read_csv('breast.csv')\n",
    "prostate_df = pd.read_csv('prostate.csv')\n",
    "\n",
    "breast_df.rename(columns={'Class': 'class'}, inplace=True)\n",
    "breast_df['class'] = breast_df['class'].map({'non-relapse': 0, 'relapse': 1})\n",
    "prostate_df['class'] = prostate_df['class'].replace(1, 0).replace(2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogRecCCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [breast_df, prostate_df]\n",
    "dataset_names = [\"Breast\", \"Prostate\"]\n",
    "lambdas = np.logspace(-4, 2, 10)\n",
    "logreg_ccd = LogRegCCD(lambdas)\n",
    "\n",
    "metrics = ['roc_auc', 'balanced_accuracy', 'recall', 'f_measure', 'precision']\n",
    "metric_values = {metric: [] for metric in metrics}\n",
    "\n",
    "for df, name in zip(datasets, dataset_names):\n",
    "    X, y = df.drop(columns=['class']).values, df['class'].values\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    logreg_ccd.fit(X_train, y_train)\n",
    "\n",
    "    logreg_ccd.validate(X_valid, y_valid)\n",
    "    y_pred_proba = logreg_ccd.predict_proba(X_test)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    metric_values['roc_auc'].append(auc)\n",
    "\n",
    "    logreg_ccd.validate(X_valid, y_valid, measure='balanced_accuracy')\n",
    "    y_pred = logreg_ccd.predict(X_test)\n",
    "    bal = logreg_ccd.compute_measure(y_test, y_pred, \"balanced_accuracy\")\n",
    "    metric_values['balanced_accuracy'].append(bal)\n",
    "\n",
    "    logreg_ccd.validate(X_valid, y_valid, measure='recall')\n",
    "    y_pred = logreg_ccd.predict(X_test)\n",
    "    recall = logreg_ccd.compute_measure(y_test, y_pred, \"recall\")\n",
    "    metric_values['recall'].append(recall)\n",
    "\n",
    "    logreg_ccd.validate(X_valid, y_valid, measure='f_measure')\n",
    "    y_pred = logreg_ccd.predict(X_test)\n",
    "    f_measure = logreg_ccd.compute_measure(y_test, y_pred, \"f_measure\")\n",
    "    metric_values['f_measure'].append(f_measure)\n",
    "\n",
    "    logreg_ccd.validate(X_valid, y_valid, measure='precision')\n",
    "    y_pred = logreg_ccd.predict(X_test)\n",
    "    prec = logreg_ccd.compute_measure(y_test, y_pred, \"precision\")\n",
    "    metric_values['precision'].append(prec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, name in zip(datasets, dataset_names):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    dataset_metric_values = [metric_values[metric][dataset_names.index(name)] for metric in metrics]\n",
    "    \n",
    "    index = np.arange(len(metrics))\n",
    "    \n",
    "    ax.bar(index, dataset_metric_values, color=['skyblue', 'lightgreen', 'salmon', 'pink', 'purple'])\n",
    "\n",
    "    ax.set_xlabel('Metric')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "    ax.set_title(f'{name} Dataset Metrics')\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.set_ylim(0, 1.1)  \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics1 = ['roc_auc', 'balanced_accuracy', 'recall', 'f_measure', 'precision']\n",
    "metric_values1 = {metric: [] for metric in metrics1}\n",
    "\n",
    "lr = LogisticRegression(penalty=None)\n",
    "\n",
    "for df, name in zip(datasets, dataset_names):\n",
    "    X, y = df.drop(columns=['class']).values, df['class'].values\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred_proba = lr.predict_proba(X_test)[:, 1] \n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    metric_values1['roc_auc'].append(auc)\n",
    "\n",
    "    bal = balanced_accuracy_score(y_test, y_pred)\n",
    "    metric_values1['balanced_accuracy'].append(bal)\n",
    "\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    metric_values1['recall'].append(recall)\n",
    "\n",
    "    f_measure = f1_score(y_test, y_pred)\n",
    "    metric_values1['f_measure'].append(f_measure)\n",
    "\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    metric_values1['precision'].append(prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for df, name in zip(datasets, dataset_names):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    dataset_metric_values = [metric_values1[metric][dataset_names.index(name)] for metric in metrics1]\n",
    "    \n",
    "    index = np.arange(len(metrics1))\n",
    "    \n",
    "    ax.bar(index, dataset_metric_values, color=['skyblue', 'lightgreen', 'salmon', 'pink', 'purple'])\n",
    "\n",
    "    ax.set_xlabel('Metric')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "    ax.set_title(f'{name} Dataset Metrics (Logistic Regression)')\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.set_ylim(0, 1.1)  \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
