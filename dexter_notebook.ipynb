{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from model import LogRegCCD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, recall_score, f1_score, roc_auc_score, balanced_accuracy_score,precision_score\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_matrix_to_df(filename):\n",
    "  data = defaultdict(dict)\n",
    "  with open(filename, 'r') as f:\n",
    "      for row_idx, line in enumerate(f):\n",
    "          for item in line.strip().split():\n",
    "              col_idx, value = item.split(':')\n",
    "              data[row_idx][int(col_idx)] = float(value)\n",
    "\n",
    "  df = pd.DataFrame.from_dict(data, orient='index').fillna(0)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dexter_train = sparse_matrix_to_df('DEXTER/dexter_train.data')\n",
    "dexter_train_y = pd.read_csv('DEXTER/dexter_train.labels', header=None)\n",
    "dexter_train_y = dexter_train_y.squeeze()\n",
    "dexter_valid =sparse_matrix_to_df('DEXTER/dexter_valid.data')\n",
    "dexter_valid_y = pd.read_csv('DEXTER/dexter_valid.labels', header=None)\n",
    "dexter_valid_y = dexter_valid_y.squeeze()\n",
    "mapping = {1: 0, -1: 1}\n",
    "dexter_train_y = dexter_train_y.map(mapping).to_numpy()\n",
    "dexter_valid_y = dexter_valid_y.map(mapping).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.linspace(10, 0.01, 10) \n",
    "model = LogRegCCD(lambdas)\n",
    "model.fit(dexter_train, dexter_train_y)\n",
    "model.validate(dexter_valid, dexter_valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.best_lambda_)\n",
    "model.plot(dexter_valid, dexter_valid_y, measure=\"roc_auc\")\n",
    "model.plot_coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.validate(dexter_valid, dexter_valid_y, measure=\"balanced_accuracy\")\n",
    "model.plot(dexter_valid, dexter_valid_y, measure=\"balanced_accuracy\")\n",
    "model.plot_coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.validate(dexter_valid, dexter_valid_y, measure=\"recall\")\n",
    "model.plot(dexter_valid, dexter_valid_y, measure=\"recall\")\n",
    "model.plot_coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.validate(dexter_valid, dexter_valid_y, measure=\"precision\")\n",
    "model.plot(dexter_valid, dexter_valid_y, measure=\"precision\")\n",
    "model.plot_coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.validate(dexter_valid, dexter_valid_y, measure=\"f_measure\")\n",
    "model.plot(dexter_valid, dexter_valid_y, measure=\"f_measure\")\n",
    "model.plot_coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLR = LogisticRegression(penalty=None)\n",
    "modelLR.fit(dexter_train, dexter_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelLR.predict(dexter_valid)\n",
    "y_prob = modelLR.predict_proba(dexter_valid)[:, 1] \n",
    "\n",
    "balanced_acc = balanced_accuracy_score(dexter_valid_y, y_pred)\n",
    "recall = recall_score(dexter_valid_y, y_pred, average='binary')\n",
    "f1 = f1_score(dexter_valid_y, y_pred, average='binary')\n",
    "roc_auc = roc_auc_score(dexter_valid_y, y_prob)\n",
    "precision = precision_score(dexter_valid_y, y_pred, average='binary')\n",
    "\n",
    "metrics = ['Balanced Accuracy', 'Recall', 'F1-Score', 'Roc-Auc', 'Precision']\n",
    "values = [balanced_acc, recall, f1, roc_auc, precision]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(metrics, values, color=['skyblue', 'lightgreen', 'salmon', 'pink', 'purple'])\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Metrics')\n",
    "plt.ylim([0, 1])  \n",
    "plt.yticks(np.linspace(0, 1, 22))  \n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
